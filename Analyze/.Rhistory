p2
z.test = function(x, pop_mean, pop_sd, side="twoside"){
sde = pop_sd / sqrt(length(x))
z = (mean(x) - pop_mean) / sde
switch(side,
twoside={
p = (1 - pnorm(abs(z))) * 2
},
less={
p = pnorm(z)
},
greater={
p = 1- pnorm(z)
}
)
return(list(z = z , p = p))
}
z.test(coke,pop_mean,pop_sd,side = "twoside")
load("riii-master/Statistics/cdc.Rdata")
names(cdc)
hist(cdc$height)
boxplot(cdc$height)
boxplot(cdc$height~ cdc$gender)
pop_mean = mean(cdc$height)
pop_sd = sd(cdc$height)
set.seed(123)
samp1 = sample(cdc[cdc$gender == 'm',]$height, 20)
boxplot(samp1)
abline(h = pop_mean, col= "red")
z   <- (mean(samp1) - pop_mean) / sde
pop_mean = mean(cdc$height)
pop_sd = sd(cdc$height)
p = (1 - pnorm(abs(z))) * 2
z.test(samp1,pop_mean,pop_sd,side = "twoside")
samp1 = sample(cdc[cdc$gender == 'm',]$height,20)
t.test(samp1,mu=pop_mean)
z.test(samp1,pop_mean,pop_sd,side = "twoside")
samp1 = sample(cdc[cdc$gender == 'm',]$height,20)
t.test(samp1,mu=pop_mean)
t1 = samp2[samp2$gender == 'm','height']
sample_index = sample(1:nrow(cdc),60)
samp2 = cdc[sample_index,c("height","gender")]
t.test(samp2$height~samp2$gender)
?t.test
t1 = samp2[samp2$gender == 'm','height']
t2 = samp2[samp2$gender == 'f','height']
t.test(x=t1,y=t2)
t.test(samp2$height~samp2$gender)
t.test(x=t1,y=t2)
sample_index = sample(1:nrow(cdc),60)
samp2 = cdc[sample_index,c("height","gender")]
t.test(samp2$height~samp2$gender)
install.packages('asbio')
library(asbio)
library(asbio)
one.sample.z(data = samp,null.mu = pop_mean,sigma = pop_sd,alternative = 'greater')
ci.mu.z(data = samp,conf = 0.95,sigma = pop_sd,summarized = T,xbar = mean(samp),n = length(samp) )
x = c(160,170,180)
y = c(64, 68, 72)
cov_xy = sum((x - mean(x)) * (y - mean(y))) / 2
cov_xy
cov(x,y)
cov_xy = sum((x - mean(x)) * (y - mean(y))) / 6
cov_xy
cor_xy = cov(x,y) / (sd(x) * sd(y))
plot(x,y)
data(mtcars)
mtcars
cov(mtcars)
cor(mtcars)
cov(mtcars[1:3])
plot(mtcars)
plot(mtcars[1:3])
plot(mtcars[1:2])
gdp = read.csv("riii-master/data/gdp.csv",header=TRUE)
gdp = gdp[1:15,]
gdp$GDP = as.numeric(sub(",", "", gdp$GDP))
gdp$Export = as.numeric(sub(",", "", gdp$Export))
cor(gdp$Export, gdp$GDP)
plot(gdp$Export, gdp$GDP)
plot(mtcars[1:3])
plot(mtcars$mpg, mtcars$cyl)
plot(mtcars$mpg, mtcars$drat)
cov(mtcars[1:3])
plot(mtcars$mpg, mtcars$disp, mtcars$drat)
plot(mtcars$mpg, mtcars$disp~ mtcars$drat)
install.packages("C50")
library(C50)
data(chunk)
data(churn)
str(churnTrain)
names(churnTrain) %in% c("state", "area_code", "account_length")
!names(churnTrain) %in% c("state", "area_code", "account_length")
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')
churnTrain=churnTrain[,variable.list]
str(churnTrain)
ind = sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset=churnTrain[ind==1,]
testset=churnTrain[ind==2,]
View(churnTrain)
set.seed(2)
ind = sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset=churnTrain[ind==1,]
testset=churnTrain[ind==2,]
View(trainset)
View(testset)
table(sample(x = 1:2,size = 100, replace=T))
set.seed(1)
table(sample(x = 1:2,size = 100, replace=T, prob=c(0.7,0.3)))
table(sample(x = 1:2,size = 100, replace=T))
names(churnTrain) %in% c("state", "area_code", "account_length")
variable.list = names(churnTrain) %in% c('state','area_code','account_length')
churnTrain=churnTrain[,variable.list]
str(churnTrain)
set.seed(2)
ind = sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset=churnTrain[ind==1,]
testset=churnTrain[ind==2,]
View(testset)
library(C50)
data(churn)
names(churnTrain) %in% c("state", "area_code", "account_length")
variable.list = names(churnTrain) %in% c('state','area_code','account_length')
churnTrain=churnTrain[,variable.list]
str(churnTrain)
set.seed(2)
ind = sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset=churnTrain[ind==1,]
testset=churnTrain[ind==2,]
install.packages('rpart')
library('rpart')
churn.rp = rpart(churn ~ ., data=trainset)
data(churn)
names(churnTrain) %in% c("state", "area_code", "account_length")
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')
churnTrain=churnTrain[,variable.list]
str(churnTrain)
set.seed(2)
ind = sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset=churnTrain[ind==1,]
testset=churnTrain[ind==2,]
churn.rp = rpart(churn ~ ., data=trainset)
churn.rp
summary(churn.rp)
par(mfrow=c(1,1))
plot(churn.rp, margin=0.1)
plot(churn.rp, margin=0.1)
plot(churn.rp, uniform=TRUE,branch = 0.6, margin=0.1)
text(churn.rp)
text(churn.rp, all=TRUE, use.n=TRUE)
plot(churn.rp, margin=0.1)
plot(churn.rp, margin = 0.1)
plot(churn.rp, margin = 0.2)
plot(churn.rp, margin = 0.01)
plot(churn.rp, uniform = TRUE, branch = 0.6, margin=0.1)
text(churn.rp, all = TRUE, use.n = TRUE)
text(churn.rp, all = TRUE, use.n = TRUE)
text(churn.rp, all = TRUE, use.n = TRUE)
plot(churn.rp, margin = 0.1)
text(churn.rp, all = TRUE, use.n = TRUE)
plot(churn.rp, margin = 0.1)
text(churn.rp)
printcp(churn.rp)
plotcp(churn.rp)
min(churn.rp$cptable[,"xerror"])
which.min(churn.rp$cptable[,"xerror"])
churn.cp = churn.rp$cptable[which.min(churn.rp$cptable[,"xerror"]), "CP"]
prune.tree=prune(churn.rp, cp=churn.cp)
plot(prune.tree, margin=0.1)
text(prune.tree, all=TRUE, use.n=TRUE, cex=0.7)
predictions = predict(prune.tree, testset, type = "class")
table(testset$churn, predictions)
predictions = predict(prune.tree, testset, type = "class")
table(testset$churn, predictions)
install.packages('caret')
install.packages('e1071')
library('caret')
library('e1071')
confusionMatrix(table(predictions, testset$churn))
install.packages("party")
library('party')
ctree.model = ctree(churn ~ . , data = trainset)
plot(ctree.model, margin=0.1)
daycharge.model = ctree(churn ~ total_day_charge + international_plan, data = trainset)
plot(daycharge.model)
ctree.predict = predict(ctree.model ,testset)
table(ctree.predict, testset$churn)
confusionMatrix(table(ctree.predict, testset$churn))
install.packages("C50")
install.packages("C50")
library(C50)
c50.model = C5.0(churn ~., data = trainset)
c=C5.0Control(minCases = 20)
c50.model = C5.0(churn ~ ., data = trainset, control = c)
summary(c50.model)
plot(c50.model)
c50.predict = predict(c50.model,testset)
table(c50.predict, testset$churn)
confusionMatrix(table(c50.predict, testset$churn))
ind = cut(1:nrow(churnTrain), breaks = 10, labels = F)
ind
accuracies = c()
for (i in 1:10) {
fit = rpart(formula = churn ~ ., data = churnTrain[ind != i,])
predictions = predict(fit, churnTrain[ind == i, ! names(churnTrain) %in% c("churn")], type="class")
correct_count = sum(predictions == churnTrain[ind == i,c("churn")])
accuracies = append(correct_count / nrow(churnTrain[ind == i,]), accuracies)
}
accuracies
mean(accuracies)
install.packages("caret")
install.packages("caret")
library(caret)
control = trainControl(method = "repeatedcv", number = 10, repeats = 3)
model = train(churn~., data = trainset, method = "rpart", trControl = control)
model
predictions = predict(model, testset)
table(predictions,testset$churn)
control = trainControl(method = "repeatedcv", number = 10, repeats = 3)
model = train(churn~., data = trainset, method = "rpart", trControl = control)
predictions = predict(model, testset)
table(predictions,testset$churn)
library('caret')
importance = varImp(model, scale=FALSE)
importance
plot(importance)
install.packages("rminer")
library(rminer)
model = fit(churn ~ ., trainset, model = "rpart")
VariableImportance = Importance(model,trainset)
VariableImportance
L = list(runs = 1, sen = t(VariableImportance$imp), sresponses = VariableImportance$sresponses)
mgraph(L,graph="IMP",leg=names(trainset),col="gray",Grid=10)
plot(importance)
mgraph(L,graph = "IMP", leg = names(trainset), col = "gray", Grid = 10)
plot(importance)
predictions = predict(churn.rp, testset)
predictions
xary = c()
yary = c()
for(i in seq(0,1,0.1)){
f <- as.factor(ifelse(predictions[,1] > i, 0, 1))
levels(f) = c("yes", "no")
tb <- table(f, testset$churn )
cm <- confusionMatrix(tb)
y = cm$byClass[1]
x = 1- cm$byClass[2]
xary = c(xary, x)
yary = c(yary, y)
}
predictions = predict(churn.rp, testset)
predictions
xary = c()
yary = c()
for(i in seq(0,1,0.1)){
f <- as.factor(ifelse(predictions[,1] > i, 0, 1))
levels(f) = c("yes", "no")
tb <- table(f, testset$churn )
cm <- confusionMatrix(tb)
y = cm$byClass[1]
x = 1- cm$byClass[2]
xary = c(xary, x)
yary = c(yary, y)
}
install.packages('caret')
install.packages('e1071')
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
library("rminer", lib.loc="~/R/win-library/3.3")
install.packages('caret')
install.packages("caret")
install.packages("caret")
library("rminer", lib.loc="~/R/win-library/3.3")
install.packages('e1071')
install.packages("e1071")
library('caret')
library('e1071')
install.packages('caret')
library('caret')
confusionMatrix(table(predictions, testset$churn))
for(i in seq(0,1,0.1)){
f = as.factor(ifelse(predictions[,1] > i, 0, 1))
levels(f) = c("yes", "no")
tb = table(f, testset$churn )
cm = confusionMatrix(tb)
y = cm$byClass[1]
x = 1- cm$byClass[2]
xary = c(xary, x)
yary = c(yary, y)
}
plot(xary,yary)
install.packages("ROCR")
library(ROCR)
predictions <-predict(churn.rp, testset, type="prob")
head(predictions)
pred.to.roc<-predictions[, 1]
head(pred.to.roc)
library(C50)
data(churn)
library(C50)
data(churn)
variable.list = !names(churnTrain) %in% c('state','area_code','account_length')
churnTrain=churnTrain[,variable.list]
str(churnTrain)
ind = sample(1:2, size=nrow(churnTrain), replace=T, prob=c(0.7, 0.3))
trainset=churnTrain[ind==1,]
testset=churnTrain[ind==2,]
View(testset)
View(trainset)
churn.rp = rpart(churn ~., data=trainset)
library(C50)
churn.rp = rpart(churn ~., data=trainset)
remove.packages("rpart", lib="C:/Program Files/R/R-3.3.3/library")
library("rpart", lib.loc="~/R/win-library/3.3")
churn.rp = rpart(churn ~., data=trainset)
summary(churn.rp)
par(mfrow = c(1,1))
plot(churn.rp, uniform = TRUE, branch = 0.6, margin = 0.1)
text(churn.rp, all = TRUE, use.n = TRUE)
min(churn.rp$cptable[,"xerror"])
which.min(churn.rp$cptable[,"xerror"])
churn.cp = churn.rp$cptable[which.min(churn.rp$cptable[,"xerror"]), "CP"]
prune.tree=prune(churn.rp, cp=churn.cp)
plot(prune.tree, margin=0.1)
text(prune.tree, all=TRUE, use.n=TRUE, cex=0.7)
predictions <-predict(prune.tree, testset)
table(testset$churn, predictions)
min(churn.rp$cptable[,"xerror"])
which.min(churn.rp$cptable[,"xerror"])
churn.cp = churn.rp$cptable[which.min(churn.rp$cptable[,"xerror"]), "CP"]
prune.tree=prune(churn.rp, cp=churn.cp)
plot(prune.tree, margin=0.1)
text(prune.tree, all=TRUE, use.n=TRUE, cex=0.7)
predictions = predict(prune.tree, testset)
table(testset$churn, predictions)
library(caret)
library(e1071)
confusionMatrix(table(predictions, testset$churn))
table(testset$churn, predictions)
View(predictions)
View(testset)
testset$churn
len(testset$churn)
length(testset$churn)
length(predictions)
View(predictions)
predictions = predict(prune.tree, testset)
table(testset$churn, predictions)
library(e1071)
confusionMatrix(table(predictions, testset$churn))
clear
?table()
table(testset$churn, predictions)
library(caret)
predict(prune.tree, testset)
predict(prune.tree, testset,type='class')
predictions=predict(prune.tree, testset,type='class')
table(testset$churn, predictions)
predictions
table(testset$churn, predictions)
library(caret)
library(e1071)
confusionMatrix(table(predictions, testset$churn))
x =c(0, 0, 1, 1, 1, 1)
y =c(1, 0, 1, 1, 0, 1)
rbind(x,y)
dist(rbind(x,y), method = "euclidean")
sqrt(sum((x-y)^2))
dist(rbind(x,y), method = "minkowski", p=2)
dist(rbind(x,y), method = "euclidean")
sqrt(sum((x-y)^2))
dist(rbind(x,y), method = "minkowski", p=2)
dist(rbind(x,y), method ="manhattan")
sum(abs(x-y))
dist(rbind(x,y), method ="minkowski", p=1)
customer = read.csv('data/customer.csv',header = TRUE)
customer = read.csv('riii-master/data/customer.csv',header = TRUE)
head(customer)
str(customer)
customer_s =scale(customer[,-1])
?scale
round(mean(customer[,2]),3)
round(sd(customer[,2]),3)
hc=hclust(dist(customer, method="euclidean"), method="ward.D2")
plot(hc, hang =-0.01, cex=0.7)
hc3 =hclust(dist(customer), method="single")
plot(hc3, hang =-0.01, cex=0.8)
install.packages('cluster')
library(cluster)
?diana
dv =diana(customer, metric ="euclidean")
summary(dv)
plot(dv)
hc2=hclust(dist(iris[,-5], method="euclidean"), method="ward.D2")
plot(hc2, hang =-0.01, cex=0.7)
fit =cutree(hc, k =4)
fit
table(fit)
plot(hc)
rect.hclust(hc, k =4, border="red")
rect.hclust(hc, k =3, border="blue")
rect.hclust(hc, k = 4 , which =4, border="red")
arplot(t(fit$centers), beside =TRUE,xlab="cluster", ylab="value")
?barplot
fit$centers
plot(c
r(customer_s)
set.seed(22)
fit =kmeans(customer_s, centers=4)
?kmeans
barplot(t(fit$centers), beside =TRUE,xlab="cluster", ylab="value")
?barplot
fit$centers
plot(cu
l.packages("cluster")
library(cluster)
clusplo
setwd("C:/Users/BIG DATA/Dropbox/Tea/Final_Project/Analyze")
library(readr)
fortest <- read_csv("C:/Users/BIG DATA/Dropbox/Tea/Final_Project/Analyze/fortest.csv",
col_names = FALSE)
View(fortest)
library("topicmodels", lib.loc="~/R/win-library/3.3")
library("lda", lib.loc="~/R/win-library/3.3")
library("LDAvis", lib.loc="~/R/win-library/3.3")
library("tm", lib.loc="~/R/win-library/3.3")
mycorpus = Corpus(VectorSource(fortest))
view(mycorpus)
head(mycorpus)
?VectorSource
mycorpus = Corpus(VectorSource(fortest$X2))
?Corpus
?DocumentTermMatrix()
y = as.DocumentTermMatrix(mycorpus)
y = DocumentTermMatrix(mycorpus)
head(y)
inspect(y)
inspect(y[1,])
inspect(y[2,])
inspect(y[3,])
inspect(y[4,])
kwlist = read_csv("kwlist.csv",col_names = FALSE)
mydoc = Corpus(VectorSource(kwlist$X2))
myDTM = DocumentTermMatrix(mydoc)
inspect(myDTM)
inspect(myDTM[1,])
myDTM[1,].length
str(myDTM[1,])
len(myDTM[1,])
length(myDTM[1,])
inspect(myDTM[,1])
myMatrix = as.matrix(myDTM)
cosine_dist_mat = 1 - crossprod_simple_triplet_matrix(myDTM)/(sqrt(col_sums(myDTM^2) %*% t(col_sums(myDTM^2))))
library("slam", lib.loc="~/R/win-library/3.3")
cosine_dist_mat = 1 - crossprod_simple_triplet_matrix(myDTM)/(sqrt(col_sums(myDTM^2) %*% t(col_sums(myDTM^2))))
?crossprod_simple_triplet_matrix
> burnin = 4000
> iter = 2000
> thin = 500
> nstart = 5
> seed = list(2003,5,63,100001,765)best = TRUE
K = 10
burnin = 4000
iter=2000
thin=500
nstart=5
seed=list(2003,5,63,100001,765)
best=TRUE
ldaOut = LDA(dtm,K,method = "Gibbs", control = list(nstart=nstart, seed=seed, best=best, burnin=burnin, iter=iter,thin=thin))
ldaOut = LDA(myDTM,K,method = "Gibbs", control = list(nstart=nstart, seed=seed, best=best, burnin=burnin, iter=iter,thin=thin))
save.image("C:/Users/BIG DATA/Dropbox/Tea/Final_Project/Analyze/R_LDA.RData")
class(ldaOut)
head(ldaOut)
inspect(ldaOut)
?LDA()
ldaOut.dim
ldaOut.Dim
ldaOut$Dim
ldaOut(Dim)
ldaOut[Dim]
dim(ldaOut)
Dim(ldaOut)
class(ldaOut)
attr(,"package")
ldaOut@Dim
ldaOut@call
ldaOut@documents
ldaOut@documents[1,]
ldaOut@documents[,1]
ldaOut@documents[1]
ldaOut@gamma
ldaOut.length
ldaOut@wordassignments
A
ldaOut@n
ldaOut@terms
gammaDF = as.data.frame(ldaOut@gamma)
head(gammaDF)
inspect(gammaDF)
gammaDF
View(gammaDF)
betaDF=as.data.frame(ldaOut@beta)
View(betaDF)
topics(ldaOut)
terms(ldaOut)
doc.topics = as.matrix(topics(ldaOut))
View(doc.topics)
write.csv(doc.topics,file = "10topics.csv")
doc.terms = as.matrix(terms(ldaOut,30))
write.csv(doc.terms,file = "30terms_of_topic.csv")
