{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\python\\lib\\site-packages\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python\\lib\\site-packages\n",
      "Requirement already satisfied: lxml in c:\\python\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import requests as r\n",
    "import json\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get urls list of x days from today ... range(-x,0)\n",
    "def getNewsList(nDays):\n",
    "    \n",
    "    articleList = []\n",
    "    \n",
    "    for delta in range(-nDays,0):\n",
    "        \n",
    "        day = date.today() + timedelta(delta)\n",
    "        daily_url = 'http://www.nytimes.com/indexes/' + day.strftime('%Y/%m/%d') + '/todayspaper/index.html'\n",
    "        \n",
    "        res = r.get(daily_url)\n",
    "        res.encoding='unicode'\n",
    "        soup = BeautifulSoup(res.text,'lxml')\n",
    "        articles = soup.select('#SpanABMiddleRegion h6 a')\n",
    "        \n",
    "        for num in range(len(articles)):\n",
    "            url_dict = {}\n",
    "            \n",
    "            url_dict['title'] = articles[num].text.strip()\n",
    "            url_dict['date'] = day.strftime('%Y/%m/%d')\n",
    "            url_dict['source'] = 'NYT'\n",
    "            url_dict['url'] = articles[num]['href']\n",
    "            articleList.append(url_dict)\n",
    "\n",
    "    return articleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get urls list of specific day\n",
    "def getOneDayNewsList(date):\n",
    "    \n",
    "    articleList = []\n",
    "        \n",
    "    daily_url = 'http://www.nytimes.com/indexes/' + date + '/todayspaper/index.html'\n",
    "        \n",
    "    res = r.get(daily_url)\n",
    "    res.encoding='unicode'\n",
    "    soup = BeautifulSoup(res.text,'lxml')\n",
    "    articles = soup.select('#SpanABMiddleRegion h6 a')\n",
    "        \n",
    "    for num in range(len(articles)):\n",
    "        url_dict = {}\n",
    "            \n",
    "        url_dict['title'] = articles[num].text.strip()\n",
    "        url_dict['date'] = date\n",
    "        url_dict['source'] = 'NYT'\n",
    "        url_dict['url'] = articles[num]['href']\n",
    "        articleList.append(url_dict)\n",
    "\n",
    "    return articleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.nytimes.com/2017/04/15/world/middleeast/alexandria-egypt-coptic-church-suicide-bombing.html?ref=todayspaper'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getOneDayNewsList('2017/04/16')[0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get article content\n",
    "def addContent(articleList):\n",
    "    \n",
    "    listIncludeContent = []    #output list\n",
    "    \n",
    "    for num in range(len(articleList)):\n",
    "                \n",
    "        res = r.get(articleList[num]['url'])\n",
    "        res.encoding='unicode'\n",
    "        soup = BeautifulSoup(res.text,'lxml')\n",
    "        contents = soup.select('.story-body-supplemental .story-body-text.story-content')\n",
    "        \n",
    "        paragraph_dict = {} \n",
    "        for numPara in range(len(contents)):\n",
    "            paragraph_dict[numPara+1] = contents[numPara].text.strip()\n",
    "        \n",
    "        article_dict = {}    #store hole article details\n",
    "        article_dict['title'] = articleList[num]['title']\n",
    "        article_dict['date'] = articleList[num]['date']\n",
    "        article_dict['source'] = articleList[num]['source']\n",
    "        article_dict['url'] = articleList[num]['url']\n",
    "        article_dict['content'] = paragraph_dict\n",
    "        \n",
    "        listIncludeContent.append(article_dict)\n",
    "            \n",
    "    return listIncludeContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def jsonOut(targetList):\n",
    "    day = date.today().strftime('%Y%m%d')\n",
    "    with open('{}_NYToutput.json'.format(day), 'w') as f:\n",
    "        json.dump(targetList, f)\n",
    "        f.close()\n",
    "    print('File {}_NYToutput.json has been created!'.format(day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170416\n",
      "20170416_NYToutput.json\n"
     ]
    }
   ],
   "source": [
    "day = date.today().strftime('%Y%m%d')\n",
    "print(day)\n",
    "print('{}_NYToutput.json'.format(day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-df5b0879b368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#debug, choose 2 articles for test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetOneDayNewsList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2016/04/16'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjsonOut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maddContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetOneDayNewsList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2016/04/16'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-8e8dcb919bc9>\u001b[0m in \u001b[0;36maddContent\u001b[0;34m(articleList)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticleList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticleList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unicode'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#debug, choose 2 articles for test\n",
    "len(getOneDayNewsList('2016/04/16'))\n",
    "jsonOut(addContent(getOneDayNewsList('2016/04/16')[0])[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
